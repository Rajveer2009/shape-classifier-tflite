{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Shape Classifier\n",
    "A simple CNN model to classify geometric shapes (circle, rectangle, square, triangle) using TensorFlow Lite."
   ],
   "id": "f5b65d4926f05e1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:33.589112Z",
     "start_time": "2025-09-18T07:17:33.584532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:34.713690Z",
     "start_time": "2025-09-18T07:17:34.711922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Variables\n",
    "DATASET_PATH = \"dataset/train\"\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ],
   "id": "95c0717eb36428ae",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:35.927256Z",
     "start_time": "2025-09-18T07:17:35.898313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42\n",
    ")"
   ],
   "id": "65a04374a475d174",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 4 classes.\n",
      "Using 192 files for training.\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:37.162174Z",
     "start_time": "2025-09-18T07:17:37.142680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validation\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42\n",
    ")"
   ],
   "id": "d203810980a31a7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 4 classes.\n",
      "Using 48 files for validation.\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:38.807801Z",
     "start_time": "2025-09-18T07:17:38.797620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n",
    "val_ds = val_ds.map(lambda x, y: (x / 255.0, y))"
   ],
   "id": "763087141ab7214d",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:17:40.138244Z",
     "start_time": "2025-09-18T07:17:40.112280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generating Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names))\n",
    "])"
   ],
   "id": "dada8b07527c8df8",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:20:33.162846Z",
     "start_time": "2025-09-18T07:20:27.427969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compiling and Training\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
   ],
   "id": "a00e8c514c595c2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - accuracy: 0.8281 - loss: 0.7999 - val_accuracy: 0.6042 - val_loss: 1.8669\n",
      "Epoch 2/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9531 - loss: 0.1158 - val_accuracy: 0.6458 - val_loss: 1.0212\n",
      "Epoch 3/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9740 - loss: 0.1067 - val_accuracy: 0.7500 - val_loss: 0.7568\n",
      "Epoch 4/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 1.0000 - loss: 0.0396 - val_accuracy: 0.7292 - val_loss: 0.8450\n",
      "Epoch 5/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.7083 - val_loss: 0.8111\n",
      "Epoch 6/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.7292 - val_loss: 0.8220\n",
      "Epoch 7/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.7083 - val_loss: 0.8598\n",
      "Epoch 8/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.7292 - val_loss: 0.9045\n",
      "Epoch 9/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.7083 - val_loss: 0.9584\n",
      "Epoch 10/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7083 - val_loss: 0.9531\n",
      "Epoch 11/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7292 - val_loss: 1.0275\n",
      "Epoch 12/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7500 - val_loss: 1.0793\n",
      "Epoch 13/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7292 - val_loss: 1.1077\n",
      "Epoch 14/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 1.0000 - loss: 9.4615e-04 - val_accuracy: 0.7500 - val_loss: 1.1627\n",
      "Epoch 15/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 1.0000 - loss: 7.3919e-04 - val_accuracy: 0.7500 - val_loss: 1.1599\n",
      "Epoch 16/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 1.0000 - loss: 6.0428e-04 - val_accuracy: 0.7500 - val_loss: 1.1931\n",
      "Epoch 17/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 1.0000 - loss: 4.4959e-04 - val_accuracy: 0.7292 - val_loss: 1.2123\n",
      "Epoch 18/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 1.0000 - loss: 3.7507e-04 - val_accuracy: 0.7292 - val_loss: 1.2369\n",
      "Epoch 19/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 1.0000 - loss: 3.1944e-04 - val_accuracy: 0.7500 - val_loss: 1.2541\n",
      "Epoch 20/20\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 1.0000 - loss: 2.6014e-04 - val_accuracy: 0.7500 - val_loss: 1.2463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x127e3fbb0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:20:33.513284Z",
     "start_time": "2025-09-18T07:20:33.192400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ],
   "id": "16af8fdf8074e652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='keras_tensor_36')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  4961505872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818333968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818332624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818334928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818334736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818334352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818335120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818333392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818333008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4818334544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758180033.408093 22893387 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1758180033.408117 22893387 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-09-18 12:50:33.408245: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7\n",
      "2025-09-18 12:50:33.408677: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-09-18 12:50:33.408684: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7\n",
      "2025-09-18 12:50:33.411784: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-09-18 12:50:33.429102: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/1k/xjscfxvj073gdcll9_hnjc5m0000gn/T/tmph0w3dcz7\n",
      "2025-09-18 12:50:33.434775: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 26533 microseconds.\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:26:43.757245Z",
     "start_time": "2025-09-18T07:26:43.744864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"models/model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Load image\n",
    "test_image = \"image.jpg\"\n",
    "img = Image.open(test_image).resize((IMG_SIZE, IMG_SIZE))\n",
    "img = np.expand_dims(np.array(img) / 255.0, axis=0).astype(np.float32)"
   ],
   "id": "edf69601c338a298",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T07:26:45.232194Z",
     "start_time": "2025-09-18T07:26:45.228160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "interpreter.set_tensor(interpreter.get_input_details()[0]['index'], img)\n",
    "interpreter.invoke()\n",
    "prediction = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
    "\n",
    "predicted_class = np.argmax(prediction)\n",
    "predicted_class_name = class_names[predicted_class].title()\n",
    "confidence = np.max(tf.nn.softmax(prediction)) * 100\n",
    "\n",
    "print(f\"Prediction: {predicted_class_name} ({confidence:.1f}%)\")"
   ],
   "id": "3c91f57a2088cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Square (100.0%)\n"
     ]
    }
   ],
   "execution_count": 94
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
